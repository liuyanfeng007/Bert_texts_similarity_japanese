{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nfrom transformers import BertJapaneseTokenizer, BertForMaskedLM\nimport pandas as pd\nimport json\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport collections\nfrom transformers import DistilBertTokenizer\nfrom transformers import TFDistilBertForSequenceClassification\nfrom transformers import DistilBertConfig","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-22T12:59:05.708333Z","iopub.execute_input":"2022-09-22T12:59:05.708698Z","iopub.status.idle":"2022-09-22T12:59:05.714654Z","shell.execute_reply.started":"2022-09-22T12:59:05.708669Z","shell.execute_reply":"2022-09-22T12:59:05.713642Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 28","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:58:57.640155Z","iopub.execute_input":"2022-09-22T12:58:57.641265Z","iopub.status.idle":"2022-09-22T12:58:57.645958Z","shell.execute_reply.started":"2022-09-22T12:58:57.641212Z","shell.execute_reply":"2022-09-22T12:58:57.644938Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = TFDistilBertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:59:10.626993Z","iopub.execute_input":"2022-09-22T12:59:10.627372Z","iopub.status.idle":"2022-09-22T12:59:12.004774Z","shell.execute_reply.started":"2022-09-22T12:59:10.627340Z","shell.execute_reply":"2022-09-22T12:59:12.003923Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\nSome layers from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing TFDistilBertForSequenceClassification: ['mlm___cls', 'bert', 'nsp___cls']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['distilbert', 'dropout_99', 'classifier', 'pre_classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyModel(tf.keras.Model):\n    def __init__(self,model):\n        super().__init__()\n        #self.model = model.distilbert(input_ids,input_mask)[0]\n        self.model = model\n        self.model.trainable = False\n        self.layersG = tf.keras.layers.GlobalMaxPool1D()\n        self.layers1 = tf.keras.layers.Dense(100, activation=\"relu\")\n        self.layersD2 = tf.keras.layers.Dropout(0.2)\n        self.layers3 = tf.keras.layers.Dense(200, activation=\"relu\")\n        self.layersD4 = tf.keras.layers.Dropout(0.2)\n        self.layers5 = tf.keras.layers.Dense(100, activation=\"relu\")\n        self.layersD6 = tf.keras.layers.Dropout(0.2)\n        self.layers7 = tf.keras.layers.Dense(50, activation=\"relu\")\n        self.layersD8 = tf.keras.layers.Dropout(0.2)\n        self.layers9 = tf.keras.layers.Dense(2, activation=\"softmax\")\n        \n        self.Bidirectional=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n    def call(self, inputs):\n        input_ids1 = inputs[\"input_ids1\"]\n        input_mask1 = inputs[\"input_mask1\"]\n        embedding_layer1  = self.model.distilbert(input_ids1,input_mask1)[0]\n        input_ids2 = inputs[\"input_ids2\"]\n        input_mask2 = inputs[\"input_mask2\"]        \n        embedding_layer2  = self.model.distilbert(input_ids2,input_mask2)[0]\n        embedding_layer = tf.concat([embedding_layer1,embedding_layer2],axis = 1)\n        X =self.Bidirectional(embedding_layer)\n        X = self.layersG(X)\n        X = self.layers1(X)\n        X = self.layersD2(X)\n        X = self.layers3(X)\n        X = self.layersD4(X)\n        X = self.layers5(X)\n        X = self.layersD6(X)\n        X = self.layers7(X)\n        X = self.layersD8(X)\n        X = self.layers9(X)        \n        return X","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:59:17.900253Z","iopub.execute_input":"2022-09-22T12:59:17.900608Z","iopub.status.idle":"2022-09-22T12:59:17.914949Z","shell.execute_reply.started":"2022-09-22T12:59:17.900580Z","shell.execute_reply":"2022-09-22T12:59:17.913938Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train_output_file = \"../input/text-data-similarity/texts_train_data.tfrecord\"\ntest_output_file = \"../input/text-data-similarity/texts_test_data.tfrecord\"","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:59:20.717980Z","iopub.execute_input":"2022-09-22T12:59:20.718361Z","iopub.status.idle":"2022-09-22T12:59:20.723270Z","shell.execute_reply.started":"2022-09-22T12:59:20.718327Z","shell.execute_reply":"2022-09-22T12:59:20.722180Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def select_data_and_label_from_record(record):\n    x = {\n        \"input_ids1\": record[\"input_ids1\"],\n        \"input_mask1\": record[\"input_mask1\"],\n        \"input_ids2\": record[\"input_ids2\"],\n        \"input_mask2\": record[\"input_mask2\"],\n        #\"segment_ids\": record[\"segment_ids\"],\n    }\n    y = record[\"label_ids\"]\n    return (x, y)\ndef _decode_record(record, name_to_features):\n    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n    return tf.io.parse_single_example(record, name_to_features)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T12:59:51.274048Z","iopub.execute_input":"2022-09-22T12:59:51.274757Z","iopub.status.idle":"2022-09-22T12:59:51.280950Z","shell.execute_reply.started":"2022-09-22T12:59:51.274719Z","shell.execute_reply":"2022-09-22T12:59:51.279886Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def create_train_test_data(file_name,isTrain = False):\n    dataset = tf.data.TFRecordDataset(file_name)\n    if isTrain :\n        dataset = dataset.repeat(500)\n    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n    name_to_features = {\n            \"input_ids1\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n            \"input_mask1\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n            \"input_ids2\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n            \"input_mask2\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n            #\"segment_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n            \"label_ids\": tf.io.FixedLenFeature([], tf.int64),\n        }\n    drop_remainder=False\n    dataset = dataset.apply(\n        tf.data.experimental.map_and_batch(\n            lambda record: _decode_record(record, name_to_features),\n            batch_size=1000,\n            drop_remainder=drop_remainder,\n            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n        )\n    )\n    dataset.cache()\n    re_dataset = dataset.map(select_data_and_label_from_record)\n    return re_dataset","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:00:13.764039Z","iopub.execute_input":"2022-09-22T13:00:13.764418Z","iopub.status.idle":"2022-09-22T13:00:13.772723Z","shell.execute_reply.started":"2022-09-22T13:00:13.764387Z","shell.execute_reply":"2022-09-22T13:00:13.771539Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_dataset = create_train_test_data(train_output_file,True)\ntest_dataset = create_train_test_data(test_output_file)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:00:22.183039Z","iopub.execute_input":"2022-09-22T13:00:22.183986Z","iopub.status.idle":"2022-09-22T13:00:22.333872Z","shell.execute_reply.started":"2022-09-22T13:00:22.183937Z","shell.execute_reply":"2022-09-22T13:00:22.332716Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_dataset","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:00:24.938848Z","iopub.execute_input":"2022-09-22T13:00:24.939231Z","iopub.status.idle":"2022-09-22T13:00:24.947164Z","shell.execute_reply.started":"2022-09-22T13:00:24.939179Z","shell.execute_reply":"2022-09-22T13:00:24.946063Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<MapDataset shapes: ({input_ids1: (None, 28), input_mask1: (None, 28), input_ids2: (None, 28), input_mask2: (None, 28)}, (None,)), types: ({input_ids1: tf.int64, input_mask1: tf.int64, input_ids2: tf.int64, input_mask2: tf.int64}, tf.int64)>"},"metadata":{}}]},{"cell_type":"code","source":"mode2 = MyModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:00:35.446162Z","iopub.execute_input":"2022-09-22T13:00:35.447152Z","iopub.status.idle":"2022-09-22T13:00:35.476109Z","shell.execute_reply.started":"2022-09-22T13:00:35.447114Z","shell.execute_reply":"2022-09-22T13:00:35.475244Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"learning_rate = 1e-3\nepsilon = 1e-6\nloss = tf.keras.losses.SparseCategoricalCrossentropy()\nmetric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\nmode2.compile(optimizer=optimizer, loss=loss, metrics=[metric])\nhistory = mode2.fit(\n    train_dataset,\n    steps_per_epoch = 20,\n    validation_data=test_dataset,\n    validation_steps=4,\n    #batch_size=50,\n    #shuffle=True,\n    epochs=200)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:00:43.987287Z","iopub.execute_input":"2022-09-22T13:00:43.987648Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/200\n20/20 [==============================] - 144s 3s/step - loss: 0.6999 - accuracy: 0.4976 - val_loss: 0.6930 - val_accuracy: 0.5033\nEpoch 2/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6939 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5063\nEpoch 3/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6935 - accuracy: 0.5027 - val_loss: 0.6928 - val_accuracy: 0.5073\nEpoch 4/200\n20/20 [==============================] - 53s 3s/step - loss: 0.6935 - accuracy: 0.4998 - val_loss: 0.6930 - val_accuracy: 0.5017\nEpoch 5/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6933 - accuracy: 0.5031 - val_loss: 0.6929 - val_accuracy: 0.5120\nEpoch 6/200\n20/20 [==============================] - 53s 3s/step - loss: 0.6930 - accuracy: 0.5127 - val_loss: 0.6925 - val_accuracy: 0.5272\nEpoch 7/200\n20/20 [==============================] - 53s 3s/step - loss: 0.6928 - accuracy: 0.5045 - val_loss: 0.6910 - val_accuracy: 0.5335\nEpoch 8/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6918 - accuracy: 0.5292 - val_loss: 0.6873 - val_accuracy: 0.5962\nEpoch 9/200\n20/20 [==============================] - 53s 3s/step - loss: 0.6814 - accuracy: 0.5635 - val_loss: 0.6491 - val_accuracy: 0.6330\nEpoch 10/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6482 - accuracy: 0.6291 - val_loss: 0.6076 - val_accuracy: 0.6670\nEpoch 11/200\n20/20 [==============================] - 52s 3s/step - loss: 0.6198 - accuracy: 0.6571 - val_loss: 0.5794 - val_accuracy: 0.7082\nEpoch 12/200\n20/20 [==============================] - 53s 3s/step - loss: 0.6048 - accuracy: 0.6702 - val_loss: 0.5615 - val_accuracy: 0.7025\nEpoch 13/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5856 - accuracy: 0.6916 - val_loss: 0.5402 - val_accuracy: 0.7255\nEpoch 14/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5701 - accuracy: 0.7048 - val_loss: 0.5381 - val_accuracy: 0.7222\nEpoch 15/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5638 - accuracy: 0.7101 - val_loss: 0.5241 - val_accuracy: 0.7400\nEpoch 16/200\n20/20 [==============================] - 53s 3s/step - loss: 0.5502 - accuracy: 0.7168 - val_loss: 0.5069 - val_accuracy: 0.7502\nEpoch 17/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5549 - accuracy: 0.7179 - val_loss: 0.5023 - val_accuracy: 0.7502\nEpoch 18/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5342 - accuracy: 0.7321 - val_loss: 0.4985 - val_accuracy: 0.7510\nEpoch 19/200\n20/20 [==============================] - 53s 3s/step - loss: 0.5214 - accuracy: 0.7401 - val_loss: 0.4886 - val_accuracy: 0.7570\nEpoch 20/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5112 - accuracy: 0.7480 - val_loss: 0.4774 - val_accuracy: 0.7768\nEpoch 21/200\n20/20 [==============================] - 52s 3s/step - loss: 0.5115 - accuracy: 0.7498 - val_loss: 0.4650 - val_accuracy: 0.7782\nEpoch 22/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4996 - accuracy: 0.7560 - val_loss: 0.4663 - val_accuracy: 0.7763\nEpoch 23/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4917 - accuracy: 0.7614 - val_loss: 0.4742 - val_accuracy: 0.7625\nEpoch 24/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4845 - accuracy: 0.7666 - val_loss: 0.4478 - val_accuracy: 0.7930\nEpoch 25/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.4343 - val_accuracy: 0.8043\nEpoch 26/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4766 - accuracy: 0.7722 - val_loss: 0.4483 - val_accuracy: 0.7853\nEpoch 27/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4733 - accuracy: 0.7742 - val_loss: 0.4407 - val_accuracy: 0.7965\nEpoch 28/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4681 - accuracy: 0.7764 - val_loss: 0.4278 - val_accuracy: 0.7995\nEpoch 29/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4566 - accuracy: 0.7831 - val_loss: 0.4311 - val_accuracy: 0.7977\nEpoch 30/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4503 - accuracy: 0.7861 - val_loss: 0.4187 - val_accuracy: 0.8080\nEpoch 31/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4515 - accuracy: 0.7890 - val_loss: 0.4202 - val_accuracy: 0.8033\nEpoch 32/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4380 - accuracy: 0.7948 - val_loss: 0.4089 - val_accuracy: 0.8135\nEpoch 33/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4361 - accuracy: 0.7944 - val_loss: 0.4000 - val_accuracy: 0.8260\nEpoch 34/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4251 - accuracy: 0.8005 - val_loss: 0.4002 - val_accuracy: 0.8177\nEpoch 35/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4271 - accuracy: 0.8015 - val_loss: 0.3855 - val_accuracy: 0.8307\nEpoch 36/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4232 - accuracy: 0.8026 - val_loss: 0.4168 - val_accuracy: 0.8073\nEpoch 37/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4226 - accuracy: 0.8097 - val_loss: 0.3864 - val_accuracy: 0.8307\nEpoch 38/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4103 - accuracy: 0.8119 - val_loss: 0.3932 - val_accuracy: 0.8163\nEpoch 39/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4119 - accuracy: 0.8113 - val_loss: 0.3782 - val_accuracy: 0.8325\nEpoch 40/200\n20/20 [==============================] - 53s 3s/step - loss: 0.4087 - accuracy: 0.8139 - val_loss: 0.3796 - val_accuracy: 0.8285\nEpoch 41/200\n20/20 [==============================] - 52s 3s/step - loss: 0.4043 - accuracy: 0.8187 - val_loss: 0.3752 - val_accuracy: 0.8317\nEpoch 42/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3924 - accuracy: 0.8234 - val_loss: 0.3827 - val_accuracy: 0.8303\nEpoch 43/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3914 - accuracy: 0.8235 - val_loss: 0.3710 - val_accuracy: 0.8382\nEpoch 44/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3854 - accuracy: 0.8253 - val_loss: 0.3778 - val_accuracy: 0.8295\nEpoch 45/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3865 - accuracy: 0.8273 - val_loss: 0.3782 - val_accuracy: 0.8300\nEpoch 46/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3819 - accuracy: 0.8302 - val_loss: 0.3686 - val_accuracy: 0.8365\nEpoch 47/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3821 - accuracy: 0.8280 - val_loss: 0.3592 - val_accuracy: 0.8385\nEpoch 48/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3799 - accuracy: 0.8288 - val_loss: 0.3862 - val_accuracy: 0.8270\nEpoch 49/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3707 - accuracy: 0.8314 - val_loss: 0.3453 - val_accuracy: 0.8508\nEpoch 50/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3767 - accuracy: 0.8295 - val_loss: 0.3769 - val_accuracy: 0.8338\nEpoch 51/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3740 - accuracy: 0.8331 - val_loss: 0.3568 - val_accuracy: 0.8432\nEpoch 52/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3622 - accuracy: 0.8438 - val_loss: 0.3566 - val_accuracy: 0.8447\nEpoch 53/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3610 - accuracy: 0.8429 - val_loss: 0.3847 - val_accuracy: 0.8288\nEpoch 54/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3617 - accuracy: 0.8403 - val_loss: 0.3854 - val_accuracy: 0.8230\nEpoch 55/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3588 - accuracy: 0.8440 - val_loss: 0.3330 - val_accuracy: 0.8530\nEpoch 56/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3566 - accuracy: 0.8421 - val_loss: 0.3365 - val_accuracy: 0.8493\nEpoch 57/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3547 - accuracy: 0.8441 - val_loss: 0.3429 - val_accuracy: 0.8460\nEpoch 58/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3487 - accuracy: 0.8490 - val_loss: 0.3245 - val_accuracy: 0.8593\nEpoch 59/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3577 - accuracy: 0.8428 - val_loss: 0.4123 - val_accuracy: 0.8008\nEpoch 60/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3494 - accuracy: 0.8497 - val_loss: 0.3260 - val_accuracy: 0.8580\nEpoch 61/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3376 - accuracy: 0.8540 - val_loss: 0.3271 - val_accuracy: 0.8577\nEpoch 62/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3426 - accuracy: 0.8495 - val_loss: 0.3278 - val_accuracy: 0.8585\nEpoch 63/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3426 - accuracy: 0.8497 - val_loss: 0.3173 - val_accuracy: 0.8600\nEpoch 64/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3388 - accuracy: 0.8504 - val_loss: 0.3091 - val_accuracy: 0.8665\nEpoch 65/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3283 - accuracy: 0.8583 - val_loss: 0.3270 - val_accuracy: 0.8522\nEpoch 66/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3386 - accuracy: 0.8530 - val_loss: 0.3129 - val_accuracy: 0.8620\nEpoch 67/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3352 - accuracy: 0.8543 - val_loss: 0.3379 - val_accuracy: 0.8472\nEpoch 68/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3231 - accuracy: 0.8619 - val_loss: 0.3225 - val_accuracy: 0.8543\nEpoch 69/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3213 - accuracy: 0.8606 - val_loss: 0.3365 - val_accuracy: 0.8530\nEpoch 70/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3312 - accuracy: 0.8565 - val_loss: 0.2989 - val_accuracy: 0.8698\nEpoch 71/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3213 - accuracy: 0.8626 - val_loss: 0.3202 - val_accuracy: 0.8568\nEpoch 72/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3232 - accuracy: 0.8604 - val_loss: 0.3252 - val_accuracy: 0.8572\nEpoch 73/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3160 - accuracy: 0.8651 - val_loss: 0.3555 - val_accuracy: 0.8397\nEpoch 74/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3311 - accuracy: 0.8579 - val_loss: 0.3098 - val_accuracy: 0.8648\nEpoch 75/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3125 - accuracy: 0.8673 - val_loss: 0.3032 - val_accuracy: 0.8685\nEpoch 76/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3146 - accuracy: 0.8655 - val_loss: 0.3336 - val_accuracy: 0.8470\nEpoch 77/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3185 - accuracy: 0.8598 - val_loss: 0.3185 - val_accuracy: 0.8562\nEpoch 78/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3037 - accuracy: 0.8709 - val_loss: 0.3264 - val_accuracy: 0.8572\nEpoch 79/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3065 - accuracy: 0.8683 - val_loss: 0.2945 - val_accuracy: 0.8712\nEpoch 80/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3127 - accuracy: 0.8670 - val_loss: 0.3236 - val_accuracy: 0.8590\nEpoch 81/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3099 - accuracy: 0.8672 - val_loss: 0.3246 - val_accuracy: 0.8522\nEpoch 82/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3048 - accuracy: 0.8699 - val_loss: 0.3107 - val_accuracy: 0.8622\nEpoch 83/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2980 - accuracy: 0.8764 - val_loss: 0.3177 - val_accuracy: 0.8553\nEpoch 84/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3044 - accuracy: 0.8684 - val_loss: 0.2972 - val_accuracy: 0.8680\nEpoch 85/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2972 - accuracy: 0.8715 - val_loss: 0.2955 - val_accuracy: 0.8727\nEpoch 86/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3028 - accuracy: 0.8717 - val_loss: 0.2990 - val_accuracy: 0.8690\nEpoch 87/200\n20/20 [==============================] - 52s 3s/step - loss: 0.3034 - accuracy: 0.8697 - val_loss: 0.2817 - val_accuracy: 0.8810\nEpoch 88/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2902 - accuracy: 0.8784 - val_loss: 0.3109 - val_accuracy: 0.8648\nEpoch 89/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2977 - accuracy: 0.8729 - val_loss: 0.2880 - val_accuracy: 0.8798\nEpoch 90/200\n20/20 [==============================] - 53s 3s/step - loss: 0.3025 - accuracy: 0.8701 - val_loss: 0.2886 - val_accuracy: 0.8780\nEpoch 91/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2816 - accuracy: 0.8813 - val_loss: 0.3058 - val_accuracy: 0.8700\nEpoch 92/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2920 - accuracy: 0.8788 - val_loss: 0.3008 - val_accuracy: 0.8662\nEpoch 93/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2884 - accuracy: 0.8783 - val_loss: 0.3128 - val_accuracy: 0.8577\nEpoch 94/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2989 - accuracy: 0.8719 - val_loss: 0.3021 - val_accuracy: 0.8715\nEpoch 95/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2910 - accuracy: 0.8763 - val_loss: 0.3173 - val_accuracy: 0.8590\nEpoch 96/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2837 - accuracy: 0.8803 - val_loss: 0.2769 - val_accuracy: 0.8802\nEpoch 99/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2775 - accuracy: 0.8836 - val_loss: 0.2931 - val_accuracy: 0.8717\nEpoch 100/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2822 - accuracy: 0.8841 - val_loss: 0.2792 - val_accuracy: 0.8798\nEpoch 101/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2660 - accuracy: 0.8908 - val_loss: 0.2802 - val_accuracy: 0.8795\nEpoch 102/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2819 - accuracy: 0.8830 - val_loss: 0.2638 - val_accuracy: 0.8885\nEpoch 103/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2800 - accuracy: 0.8841 - val_loss: 0.2721 - val_accuracy: 0.8855\nEpoch 104/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2799 - accuracy: 0.8810 - val_loss: 0.2916 - val_accuracy: 0.8730\nEpoch 105/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2758 - accuracy: 0.8813 - val_loss: 0.2928 - val_accuracy: 0.8683\nEpoch 106/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2791 - accuracy: 0.8837 - val_loss: 0.2983 - val_accuracy: 0.8658\nEpoch 107/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2747 - accuracy: 0.8864 - val_loss: 0.2909 - val_accuracy: 0.8662\nEpoch 108/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2723 - accuracy: 0.8856 - val_loss: 0.2924 - val_accuracy: 0.8727\nEpoch 109/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2726 - accuracy: 0.8862 - val_loss: 0.3356 - val_accuracy: 0.8475\nEpoch 110/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2739 - accuracy: 0.8845 - val_loss: 0.2986 - val_accuracy: 0.8690\nEpoch 111/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2658 - accuracy: 0.8892 - val_loss: 0.2882 - val_accuracy: 0.8775\nEpoch 112/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2693 - accuracy: 0.8852 - val_loss: 0.3036 - val_accuracy: 0.8620\nEpoch 113/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2759 - accuracy: 0.8850 - val_loss: 0.3212 - val_accuracy: 0.8520\nEpoch 114/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2692 - accuracy: 0.8881 - val_loss: 0.2718 - val_accuracy: 0.8855\nEpoch 115/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2741 - accuracy: 0.8860 - val_loss: 0.2538 - val_accuracy: 0.8960\nEpoch 116/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2727 - accuracy: 0.8857 - val_loss: 0.3114 - val_accuracy: 0.8575\nEpoch 117/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2593 - accuracy: 0.8920 - val_loss: 0.2755 - val_accuracy: 0.8805\nEpoch 118/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2589 - accuracy: 0.8927 - val_loss: 0.2983 - val_accuracy: 0.8710\nEpoch 119/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2617 - accuracy: 0.8910 - val_loss: 0.2850 - val_accuracy: 0.8775\nEpoch 120/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2573 - accuracy: 0.8940 - val_loss: 0.2962 - val_accuracy: 0.8725\nEpoch 121/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2604 - accuracy: 0.8930 - val_loss: 0.3004 - val_accuracy: 0.8690\nEpoch 122/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2566 - accuracy: 0.8924 - val_loss: 0.2883 - val_accuracy: 0.8737\nEpoch 123/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.2587 - val_accuracy: 0.8907\nEpoch 124/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2557 - accuracy: 0.8939 - val_loss: 0.2831 - val_accuracy: 0.8810\nEpoch 125/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2602 - accuracy: 0.8932 - val_loss: 0.2827 - val_accuracy: 0.8752\nEpoch 126/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2558 - accuracy: 0.8957 - val_loss: 0.2793 - val_accuracy: 0.8815\nEpoch 127/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2567 - accuracy: 0.8952 - val_loss: 0.2588 - val_accuracy: 0.8907\nEpoch 128/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2517 - accuracy: 0.8978 - val_loss: 0.2869 - val_accuracy: 0.8810\nEpoch 129/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2582 - accuracy: 0.8917 - val_loss: 0.2753 - val_accuracy: 0.8810\nEpoch 130/200\n20/20 [==============================] - 53s 3s/step - loss: 0.2515 - accuracy: 0.8949 - val_loss: 0.2544 - val_accuracy: 0.8885\nEpoch 131/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2507 - accuracy: 0.8953 - val_loss: 0.2781 - val_accuracy: 0.8733\nEpoch 132/200\n20/20 [==============================] - 52s 3s/step - loss: 0.2430 - accuracy: 0.9014 - val_loss: 0.2708 - val_accuracy: 0.8810\nEpoch 133/200\n10/20 [==============>...............] - ETA: 22s - loss: 0.2541 - accuracy: 0.8971","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}